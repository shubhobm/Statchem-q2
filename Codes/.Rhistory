folds = createFolds(1:n, k=5)
pb = txtProgressBar(0,5)
for(i in 1:5){
test = folds[[i]]
cv.obj1 = cv.glmnet(X[-test,],y[-test])
err.vec1[i] = mean((y[test] - predict(cv.obj1, X[test,], s="lambda.min"))^2)
setTxtProgressBar(pb,i)
}
close(pb)
dim(X)
View(X)
y
y = lta98$Y[-1]
X = with(lta98, cbind(ltaTS,ltaTC,lta3D, ltaQC))[-1,]
n = nrow(X)
p = ncol(X)
## shall use LASSO
## 5-fold cv
cat("5-fold cv\n")
err.vec1 = rep(0,5)
folds = createFolds(1:n, k=5)
pb = txtProgressBar(0,5)
for(i in 1:5){
test = folds[[i]]
cv.obj1 = cv.glmnet(X[-test,],y[-test])
err.vec1[i] = mean((y[test] - predict(cv.obj1, X[test,], s="lambda.min"))^2)
setTxtProgressBar(pb,i)
}
close(pb)
class(Y)
class(y)
class(X)
y = lta98$Y[-1]
X = as.matrix(with(lta98, cbind(ltaTS,ltaTC,lta3D, ltaQC))[-1,])
n = nrow(X)
p = ncol(X)
## shall use LASSO
## 5-fold cv
cat("5-fold cv\n")
err.vec1 = rep(0,5)
folds = createFolds(1:n, k=5)
pb = txtProgressBar(0,5)
for(i in 1:5){
test = folds[[i]]
cv.obj1 = cv.glmnet(X[-test,],y[-test])
err.vec1[i] = mean((y[test] - predict(cv.obj1, X[test,], s="lambda.min"))^2)
setTxtProgressBar(pb,i)
}
close(pb)
cat("LOO cv\n")
err.vec2 = rep(0,100)
pb = txtProgressBar(0,100)
for(rep2 in 1:100){
cv.obj2 = cv.glmnet(X[-rep2,],y[-rep2])
err.vec2[rep2] = (y[rep2] - sum(c(1,X[rep2,]) * as.numeric(coef(cv.obj2, s="lambda.min"))))^2
setTxtProgressBar(pb,rep2)
}
close(pb)
rep2
set.seed(07072017)
y = lta98$Y[-1]
X = as.matrix(with(lta98, cbind(ltaTS,ltaTC,lta3D, ltaQC))[-1,])
n = nrow(X)
p = ncol(X)
n
p
dim(X)
dim(Y)
cat("5-fold cv\n")
err.vec1 = rep(0,5)
folds = createFolds(1:n, k=5)
pb = txtProgressBar(0,5)
for(i in 1:5){
test = folds[[i]]
cv.obj1 = cv.glmnet(X[-test,],y[-test])
err.vec1[i] = mean((y[test] - predict(cv.obj1, X[test,], s="lambda.min"))^2)
setTxtProgressBar(pb,i)
}
close(pb)
## LOO cv
cat("LOO cv\n")
err.vec2 = rep(0,100)
pb = txtProgressBar(0,100)
for(rep2 in 1:100){
cv.obj2 = cv.glmnet(X[-rep2,],y[-rep2])
err.vec2[rep2] = (y[rep2] - sum(c(1,X[rep2,]) * as.numeric(coef(cv.obj2, s="lambda.min"))))^2
setTxtProgressBar(pb,rep2)
}
close(pb)
cat("LOO cv\n")
err.vec2 = rep(0,100)
pb = txtProgressBar(0,100)
for(rep2 in 1:n){
cv.obj2 = cv.glmnet(X[-rep2,],y[-rep2])
err.vec2[rep2] = (y[rep2] - sum(c(1,X[rep2,]) * as.numeric(coef(cv.obj2, s="lambda.min"))))^2
setTxtProgressBar(pb,rep2)
}
close(pb)
cat("repeated external cv\n")
err.vec4 = rep(0,100)
pb = txtProgressBar(0,100)
for(rep4 in 1:100){
test = sample(1:n, 10, replace=F)
cv.obj4 = cv.glmnet(X[-test,],y[-test])
err.vec4[rep4] = mean((y[test] - predict(cv.obj4, X[test,], s="lambda.min"))^2)
setTxtProgressBar(pb,rep4)
}
close(pb)
out.all = c(mean(err.vec1), mean(err.vec2), err.vec4)
out.all[1]
out.all[2]
mean(out.all[-(1:2)])
min(out.all[-(1:2)])
hist(out.all)
set.seed(07072017)
X = matrix(rnorm(n*p), nrow=n)
beta = c(rep(1,10), rep(0,p-10))
e = rnorm(n)
y = X %*% beta + e
## actual signal
err0 = sum(e^2)
err0
err0 = mean(e^2)
err0
err0 = c(mean(e^2), mean(e^2)/mean(y^2))
err0
err0 = c(mean(e^2), 1-mean(e^2)/mean(y^2))
err0
cat("5-fold cv\n")
err.mat1 = matrix(0, nrow=5, ncol=2)
folds = createFolds(1:n, k=5)
pb = txtProgressBar(0,5)
for(i in 1:5){
test = folds[[i]]
cv.obj1 = cv.glmnet(X[-test,],y[-test])
err1 = mean((y[test] - predict(cv.obj1, X[test,], s="lambda.min"))^2)
err.mat1[i] = c(err1, 1- err1/mean(y[test]^2))
setTxtProgressBar(pb,i)
}
close(pb)
mean((y[test] - predict(cv.obj1, X[test,], s="lambda.min"))^2)
set.seed(07072017)
X = matrix(rnorm(n*p), nrow=n)
beta = c(rep(1,10), rep(0,p-10))
e = rnorm(n)
y = X %*% beta + e
## actual signal
err0 = c(mean(e^2), 1-mean(e^2)/mean(y^2))
## shall use LASSO
## 5-fold cv
cat("5-fold cv\n")
err.mat1 = matrix(0, nrow=5, ncol=2)
folds = createFolds(1:n, k=5)
pb = txtProgressBar(0,5)
for(i in 1:5){
test = folds[[i]]
cv.obj1 = cv.glmnet(X[-test,],y[-test])
err1 = mean((y[test] - predict(cv.obj1, X[test,], s="lambda.min"))^2)
err.mat1[i] = c(err1, 1- err1/mean(y[test]^2))
setTxtProgressBar(pb,i)
}
close(pb)
err.mat1[i,] = c(err1, 1- err1/mean(y[test]^2))
p
set.seed(07072017)
X = matrix(rnorm(n*p), nrow=n)
beta = c(rep(1,10), rep(0,p-10))
e = rnorm(n)
y = X %*% beta + e
## actual signal
err0 = c(mean(e^2), 1-mean(e^2)/mean(y^2))
## shall use LASSO
## 5-fold cv
cat("5-fold cv\n")
err.mat1 = matrix(0, nrow=5, ncol=2)
folds = createFolds(1:n, k=5)
pb = txtProgressBar(0,5)
for(i in 1:5){
test = folds[[i]]
cv.obj1 = cv.glmnet(X[-test,],y[-test])
err1 = mean((y[test] - predict(cv.obj1, X[test,], s="lambda.min"))^2)
err.mat1[i,] = c(err1, 1- err1/mean(y[test]^2))
setTxtProgressBar(pb,i)
}
close(pb)
err.mat1
err0
colMeans(err.mat1)
err.mat2[rep2] = c(err2, 1- err2/mean(y[rep2]^2))
cat("LOO cv\n")
err.vec2 = matrix(0, nrow=100, ncol=2)
pb = txtProgressBar(0,100)
for(rep2 in 1:100){
cv.obj2 = cv.glmnet(X[-rep2,],y[-rep2])
err2 = (y[rep2] - sum(c(1,X[rep2,]) * as.numeric(coef(cv.obj2, s="lambda.min"))))^2
err.mat2[rep2] = c(err2, 1- err2/mean(y[rep2]^2))
setTxtProgressBar(pb,rep2)
}
close(pb)
cat("LOO cv\n")
err.mat2 = matrix(0, nrow=100, ncol=2)
pb = txtProgressBar(0,100)
for(rep2 in 1:100){
cv.obj2 = cv.glmnet(X[-rep2,],y[-rep2])
err2 = (y[rep2] - sum(c(1,X[rep2,]) * as.numeric(coef(cv.obj2, s="lambda.min"))))^2
err.mat2[rep2] = c(err2, 1- err2/mean(y[rep2]^2))
setTxtProgressBar(pb,rep2)
}
close(pb)
rep2
n
cat("LOO cv\n")
err.mat2 = matrix(0, nrow=100, ncol=2)
pb = txtProgressBar(0,n)
for(rep2 in 1:n){
cv.obj2 = cv.glmnet(X[-rep2,],y[-rep2])
err2 = (y[rep2] - sum(c(1,X[rep2,]) * as.numeric(coef(cv.obj2, s="lambda.min"))))^2
err.mat2[rep2] = c(err2, 1- err2/mean(y[rep2]^2))
setTxtProgressBar(pb,rep2)
}
close(pb)
cat("LOO cv\n")
err.mat2 = matrix(0, nrow=100, ncol=2)
pb = txtProgressBar(0,n)
for(rep2 in 1:n){
cv.obj2 = cv.glmnet(X[-rep2,],y[-rep2])
err2 = (y[rep2] - sum(c(1,X[rep2,]) * as.numeric(coef(cv.obj2, s="lambda.min"))))^2
err.mat2[rep2,] = c(err2, 1- err2/mean(y[rep2]^2))
setTxtProgressBar(pb,rep2)
}
close(pb)
cat("LOO cv\n")
err.mat2 = matrix(0, nrow=n, ncol=2)
pb = txtProgressBar(0,n)
for(rep2 in 1:n){
cv.obj2 = cv.glmnet(X[-rep2,],y[-rep2])
err2 = (y[rep2] - sum(c(1,X[rep2,]) * as.numeric(coef(cv.obj2, s="lambda.min"))))^2
err.mat2[rep2,] = c(err2, 1- err2/mean(y[rep2]^2))
setTxtProgressBar(pb,rep2)
}
close(pb)
colMeans(err.mat2)
err.mat2
1- err2/y[rep2]^2)
1- err2/y[rep2]^2
cat("LOO cv\n")
err.mat2 = matrix(0, nrow=n, ncol=2)
pb = txtProgressBar(0,n)
for(rep2 in 1:n){
cv.obj2 = cv.glmnet(X[-rep2,],y[-rep2])
err2 = (y[rep2] - sum(c(1,X[rep2,]) * as.numeric(coef(cv.obj2, s="lambda.min"))))^2
err.mat2[rep2,] = c(err2, 1- err2/y[rep2]^2)
setTxtProgressBar(pb,rep2)
}
close(pb)
colMeans(err.mat2)
err2
cat("LOO cv\n")
err.vec2 = rep(0,n)
pb = txtProgressBar(0,n)
for(rep2 in 1:n){
cv.obj2 = cv.glmnet(X[-rep2,],y[-rep2])
err.vec2[rep2] = (y[rep2] - sum(c(1,X[rep2,]) * as.numeric(coef(cv.obj2, s="lambda.min"))))^2
setTxtProgressBar(pb,rep2)
}
close(pb)
mean(err.vec2)
n
n = 100
p=100
set.seed(07072017)
X = matrix(rnorm(n*p), nrow=n)
beta = c(rep(1,10), rep(0,p-10))
e = rnorm(n)
y = X %*% beta + e
## actual signal
err0 = c(mean(e^2), 1-mean(e^2)/mean(y^2))
## shall use LASSO
## 5-fold cv
cat("5-fold cv\n")
err.mat1 = matrix(0, nrow=5, ncol=2)
folds = createFolds(1:n, k=5)
pb = txtProgressBar(0,5)
for(i in 1:5){
test = folds[[i]]
cv.obj1 = cv.glmnet(X[-test,],y[-test])
err1 = mean((y[test] - predict(cv.obj1, X[test,], s="lambda.min"))^2)
err.mat1[i,] = c(err1, 1- err1/mean(y[test]^2))
setTxtProgressBar(pb,i)
}
close(pb)
err.mat1
err0
## LOO cv
cat("LOO cv\n")
err.vec2 = rep(0,n)
pb = txtProgressBar(0,n)
for(rep2 in 1:n){
cv.obj2 = cv.glmnet(X[-rep2,],y[-rep2])
err.vec2[rep2] = (y[rep2] - sum(c(1,X[rep2,]) * as.numeric(coef(cv.obj2, s="lambda.min"))))^2
setTxtProgressBar(pb,rep2)
}
close(pb)
mean(err.vec2)
colMeans(err.mat1)
mean(err.vec2)/mean(y^2)
1-mean(err.vec2)/mean(y^2)
cat("repeated external cv\n")
err.mat4 = matrix(0, nrow=100, ncol=2)
pb = txtProgressBar(0,100)
for(rep4 in 1:100){
test = sample(1:n, 10, replace=F)
cv.obj4 = cv.glmnet(X[-test,],y[-test])
err4 = mean((y[test] - predict(cv.obj4, X[test,], s="lambda.min"))^2)
err.mat4[rep4,] = c(err4, 1- err4/mean(y[test]^2))
setTxtProgressBar(pb,rep4)
}
close(pb)
colMeans(err.mat4)
err0
rbind(err0,
colMeans(err.mat1),
c(mean(err.vec2), 1-mean(err.vec2)/mean(y^2)),
err.mat4)
dim(  rbind(err0,
colMeans(err.mat1),
c(mean(err.vec2), 1-mean(err.vec2)/mean(y^2)),
err.mat4))
rm(list=ls())
setwd('D:/Study/My projects/Statchem-q2/Codes')
library(glmnet)
library(caret)
## generate data
n = 100
do.all = function(p){
set.seed(07072017)
X = matrix(rnorm(n*p), nrow=n)
beta = c(rep(1,10), rep(0,p-10))
e = rnorm(n)
y = X %*% beta + e
## actual signal
err0 = c(mean(e^2), 1-mean(e^2)/mean(y^2))
## shall use LASSO
## 5-fold cv
cat("5-fold cv\n")
err.mat1 = matrix(0, nrow=5, ncol=2)
folds = createFolds(1:n, k=5)
pb = txtProgressBar(0,5)
for(i in 1:5){
test = folds[[i]]
cv.obj1 = cv.glmnet(X[-test,],y[-test])
err1 = mean((y[test] - predict(cv.obj1, X[test,], s="lambda.min"))^2)
err.mat1[i,] = c(err1, 1- err1/mean(y[test]^2))
setTxtProgressBar(pb,i)
}
close(pb)
## LOO cv
cat("LOO cv\n")
err.vec2 = rep(0,n)
pb = txtProgressBar(0,n)
for(rep2 in 1:n){
cv.obj2 = cv.glmnet(X[-rep2,],y[-rep2])
err.vec2[rep2] = (y[rep2] - sum(c(1,X[rep2,]) * as.numeric(coef(cv.obj2, s="lambda.min"))))^2
setTxtProgressBar(pb,rep2)
}
close(pb)
## external validation
# test = sample(1:n, 10, replace=F)
# cv.obj3 = cv.glmnet(X[-test,],y[-test])
# mean((y[test] - predict(cv.obj3, X[test,], s="lambda.min"))^2)
## repeated external validation
cat("repeated external cv\n")
err.mat4 = matrix(0, nrow=100, ncol=2)
pb = txtProgressBar(0,100)
for(rep4 in 1:100){
test = sample(1:n, 10, replace=F)
cv.obj4 = cv.glmnet(X[-test,],y[-test])
err4 = mean((y[test] - predict(cv.obj4, X[test,], s="lambda.min"))^2)
err.mat4[rep4,] = c(err4, 1- err4/mean(y[test]^2))
setTxtProgressBar(pb,rep4)
}
close(pb)
## return
rbind(err0,
colMeans(err.mat1),
c(mean(err.vec2), 1-mean(err.vec2)/mean(y^2)),
err.mat4)
}
out100 = do.all(100)
out500 = do.all(500)
out1000 = do.all(1000)
out.all = list(out100, out500, out1000)
save(out.all, file="out_simulation.Rda")
set.seed(07072017)
y = lta98$Y[-1]
X = as.matrix(with(lta98, cbind(ltaTS,ltaTC,lta3D, ltaQC))[-1,])
n = nrow(X)
p = ncol(X)
## shall use LASSO
## 5-fold cv
cat("5-fold cv\n")
err.mat1 = matrix(0, nrow=5, ncol=2)
folds = createFolds(1:n, k=5)
pb = txtProgressBar(0,5)
for(i in 1:5){
test = folds[[i]]
cv.obj1 = cv.glmnet(X[-test,],y[-test])
err1 = mean((y[test] - predict(cv.obj1, X[test,], s="lambda.min"))^2)
err.mat1[i,] = c(err1, 1- err1/mean(y[test]^2))
setTxtProgressBar(pb,i)
}
close(pb)
## LOO cv
cat("LOO cv\n")
err.vec2 = rep(0,n)
pb = txtProgressBar(0,n)
for(rep2 in 1:n){
cv.obj2 = cv.glmnet(X[-rep2,],y[-rep2])
err.vec2[rep2] = (y[rep2] - sum(c(1,X[rep2,]) * as.numeric(coef(cv.obj2, s="lambda.min"))))^2
setTxtProgressBar(pb,rep2)
}
close(pb)
## external validation
# test = sample(1:n, 10, replace=F)
# cv.obj3 = cv.glmnet(X[-test,],y[-test])
# mean((y[test] - predict(cv.obj3, X[test,], s="lambda.min"))^2)
## repeated external validation
cat("repeated external cv\n")
err.mat4 = matrix(0, nrow=100, ncol=2)
pb = txtProgressBar(0,100)
for(rep4 in 1:100){
test = sample(1:n, 10, replace=F)
cv.obj4 = cv.glmnet(X[-test,],y[-test])
err4 = mean((y[test] - predict(cv.obj4, X[test,], s="lambda.min"))^2)
err.mat4[rep4,] = c(err4, 1- err4/mean(y[test]^2))
setTxtProgressBar(pb,rep4)
}
close(pb)
## return
out.all = rbind(err0,
colMeans(err.mat1),
c(mean(err.vec2), 1-mean(err.vec2)/mean(y^2)),
err.mat4)
load('../Data/lta98.rda')
set.seed(07072017)
y = lta98$Y[-1]
X = as.matrix(with(lta98, cbind(ltaTS,ltaTC,lta3D, ltaQC))[-1,])
n = nrow(X)
p = ncol(X)
cat("5-fold cv\n")
err.mat1 = matrix(0, nrow=5, ncol=2)
folds = createFolds(1:n, k=5)
pb = txtProgressBar(0,5)
for(i in 1:5){
test = folds[[i]]
cv.obj1 = cv.glmnet(X[-test,],y[-test])
err1 = mean((y[test] - predict(cv.obj1, X[test,], s="lambda.min"))^2)
err.mat1[i,] = c(err1, 1- err1/mean(y[test]^2))
setTxtProgressBar(pb,i)
}
close(pb)
## LOO cv
cat("LOO cv\n")
err.vec2 = rep(0,n)
pb = txtProgressBar(0,n)
for(rep2 in 1:n){
cv.obj2 = cv.glmnet(X[-rep2,],y[-rep2])
err.vec2[rep2] = (y[rep2] - sum(c(1,X[rep2,]) * as.numeric(coef(cv.obj2, s="lambda.min"))))^2
setTxtProgressBar(pb,rep2)
}
close(pb)
## external validation
# test = sample(1:n, 10, replace=F)
# cv.obj3 = cv.glmnet(X[-test,],y[-test])
# mean((y[test] - predict(cv.obj3, X[test,], s="lambda.min"))^2)
## repeated external validation
cat("repeated external cv\n")
err.mat4 = matrix(0, nrow=100, ncol=2)
pb = txtProgressBar(0,100)
for(rep4 in 1:100){
test = sample(1:n, 10, replace=F)
cv.obj4 = cv.glmnet(X[-test,],y[-test])
err4 = mean((y[test] - predict(cv.obj4, X[test,], s="lambda.min"))^2)
err.mat4[rep4,] = c(err4, 1- err4/mean(y[test]^2))
setTxtProgressBar(pb,rep4)
}
close(pb)
## return
out.all = rbind(err0,
colMeans(err.mat1),
c(mean(err.vec2), 1-mean(err.vec2)/mean(y^2)),
err.mat4)
out.all = rbind(colMeans(err.mat1),
c(mean(err.vec2), 1-mean(err.vec2)/mean(y^2)),
err.mat4)
out.all[1:2,]
colMeans(out.all[-(1:2),]
)
colMeans(err.mat1)
colMeans(err.mat4)
plot(density(Err.mat4[,2]))
plot(density(err.mat4[,2]))
abline(v=1-mean(err.vec2)/mean(y^2)))
abline(v=1-mean(err.vec2)/mean(y^2))
abline(v=colMeans(err.mat1)[2], lty=2)
abline(v=colMeans(err.mat4)[2], lty=3)
abline(v=apply(err.mat4,2,median)[2], lty=3)
apply(err.mat4,2,median)
out.all = rbind(colMeans(err.mat1),
c(mean(err.vec2), 1-mean(err.vec2)/mean(y^2)),
err.mat4)
save(out.all, file="out_lta98.Rda")
